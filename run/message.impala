extern "C" {
    fn printString(&[u8]) -> ();
    fn printFloat(f32) -> ();
    fn printDouble(f64) -> ();
    fn printInteger(i32) -> ();
    fn log(f64) -> (f64);
    fn exp(f64) -> (f64);
    fn logf(f32) -> (f32);
    fn lgamma(f64) -> (f64);
    fn randomDouble(f64, f64) -> (f64);
}


fn range(mut b: i32, e: i32, body: fn(i32) -> ()) -> () {
    while b < e {
        body(b++)
    }
}

fn @(true) max(a: f64, b: f64) -> (f64){
    if a > b{
        a
    }else{
        b
    }
}

fn @(true) relu( x: f64 ) -> (f64){
    if(x>=0.0){
        x
    }else{
        0.1 * x
    }
}

fn @(true) softmax(input: &[f64], output: &mut[f64], size: i32) -> (f64){
  let mut sum = 0.0;
  let mut i = 0;

  while(i < size){
    let e = exp(input(i));
    sum += e;
    output(i) = e;
    i++;
  }

  i = 0;
  while(i < size){
    output(i) = output(i) / sum;
    i++;
  }

  0.0
}

fn @(true) fully_connected(input: &[f64], output: &mut[f64], weights: &[f64], input_size: i32, output_size: i32) -> (f64){
  let mut i = 0;
  while(i < output_size){
    let mut value = 0.0;
    let mut j = 0;

    while(j < input_size){
      value += input(j) * weights(j + i * output_size);
      j++;
    }

    output(i) = relu(value);
    i++;
  }
  0.0
}

fn @(true) max_pooling(input: &[f64], output: &mut[f64], size_x:i32, size_y:i32, size_z:i32) -> (f64){
  let mut z_i = 0;
  while( z_i < size_z) {
    let feature_offset = z_i * size_y * size_x;
    let mut x_i = 0;
    while ( x_i <= size_x - 2) {
      let mut y_i = 0;
      while(y_i <= size_y - 2){

        let index = (z_i * size_y / 2 + y_i / 2 ) * size_x / 2 + x_i / 2;
        output(index) = max(
          max(
            input(feature_offset + y_i * size_x + x_i),
            input(feature_offset + y_i * size_x + x_i + 1)
          ),
          max(
            input(feature_offset + (y_i + 1) * size_x + x_i),
            input(feature_offset + (y_i + 1) * size_x + x_i + 1)
          )
        );

        y_i += 2;
      }

      x_i += 2;
    }

    z_i++;
  }

  0.0
}

fn @(true) conv_layer(input: &[f64], output: &mut[f64], weights: &[f64], kernel_size: i32, size_x: i32, size_y: i32, input_features: i32, output_features: i32) -> (f64){

  let offset: i32 = 2;

  let x_out_size = size_x - kernel_size;
  let y_out_size = size_y - kernel_size;


  let mut index = 0;
  while(index < output_features * x_out_size * y_out_size){
    let y_i = index % y_out_size;
    let xz_index = index / y_out_size;
    let x_i = xz_index % x_out_size;
    let z_i = xz_index / x_out_size;
    let mut value = 0.0;
    let mut kernel_index = 0;

    while (kernel_index < (input_features * kernel_size * kernel_size)) {
        let offset_x = offset % kernel_size;
        let feature_y_index = offset / kernel_size;

        let offset_y = feature_y_index % kernel_size;
        let feature_i = feature_y_index / kernel_size;

        let data_index = feature_i * size_y * size_x + (y_i + offset_y) * size_x + x_i + offset_x;
        let weight_index = offset_x + (offset_y + feature_i * kernel_size) * kernel_size;
        value += input(data_index) * weights(weight_index);
        kernel_index++;
    }

    output((z_i * size_y + y_i + offset) * size_x + x_i + offset) = relu(value);

    index++;
  }

  0.0
}


fn runNnBenchmark(file: &[u8]) -> (){

    let size_x = 28;
    let size_y = 28;
    let kernel_size = 5;

    let kernel_size_sqr = kernel_size * kernel_size;
    
    let convolution_size_1 = kernel_size_sqr * 8;
    let convolution_size_2 = kernel_size_sqr * 16;
    
    let fully_connected_size_1 = convolution_size_2 * 256;
    let fully_connected_size_2 = 256 * 10;
    
    let weight_size = convolution_size_1 + convolution_size_2 + fully_connected_size_1 + fully_connected_size_2;

    let first_weights_size = 28*28*32;
    let first_weights = ~[first_weights_size:f64];

    let second_weights_size = 32*10;
    let second_weights = ~[second_weights_size:f64];

    for i in range(0, weight_size){
        first_weights(i) = randomDouble(-0.1, 0.1);
    }

    for i in range(0, second_weights_size){
        second_weights(i) = randomDouble(-0.1, 0.1);
    }

    let input = ~[28*28:f64];
    let output = ~[10:f64];

    for i in range(0, 28*28){
        input(i) = randomDouble(0.0, 1.0);
    }

    let label: i32 = 1;

    let Df = rev_diff(loss);
    let (y,pb) = Df((first_weights_size as u64, first_weights),
                (second_weights_size as u64, second_weights),
                ((28*28) as u64, input), label);

    let gradients = pb(1.0);
    let (first_weights_d_size, first_weights_d) = gradients(0);
    let (second_weights_d_size, second_weights_d) = gradients(1);

    printString("conv weights 1");
    for i in range(0, first_weights_d_size as i32){
        printDouble(first_weights_d(i));
    }

    printString("conv weights 2");
    for i in range(0, second_weights_d_size as i32){
        printDouble(second_weights_d(i));
    }

    printString("loss");
    printDouble(y);

    printString("prediction");

    let hidden = ~[32:f64];
    fully_connected(input, hidden, first_weights, 28*28, 32);
    fully_connected(hidden, output, second_weights, 32, 10);

    softmax(output, output, 10);

    for i in range(0, 10){
        printDouble(output(i));
    }
}

fn @(true) cross_entropy(output: &[f64], target: i32) -> (f64){
  -log(output(target))
}

fn loss(
    first_weights: &[f64],
    second_weights: &[f64],
    input: &[f64],
    target: i32 ) -> (f64){

  let output = ~[10:f64];
  let output_softmax = ~[10:f64];
  let hidden = ~[32:f64];
  fully_connected(input, hidden, first_weights, 28*28, 32);
  fully_connected(hidden, output, second_weights, 32, 10);
  softmax(output, output_softmax, 10);
  cross_entropy(output_softmax, target)
}

fn main(argc: i32,argv :&[&[u8]]) -> i32 {
    if argc < 2{
        printString("No Benchmark specified");
    }else{
        let file = argv(1);
        printString(file);
        runNnBenchmark(file);
    }

    0
}


